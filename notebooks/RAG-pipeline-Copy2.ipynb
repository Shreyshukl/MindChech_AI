{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277b707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index and metadata loaded. Ready for search!\n"
     ]
    }
   ],
   "source": [
    "import faiss, pickle\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"faiss_index.bin\")\n",
    "\n",
    "# Load metadata\n",
    "with open(\"metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "print(\"âœ… FAISS index and metadata loaded. Ready for search!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061d2a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… text loaded. Ready for search!\n"
     ]
    }
   ],
   "source": [
    "with open(\"texts.pkl\", \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "print(\"âœ… text loaded. Ready for search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983f577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94784edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=5):\n",
    "    \"\"\"Search similar cases from FAISS index.\"\"\"\n",
    "    query_with_prefix = f\"query: {query}\"\n",
    "    query_vec = model.encode([query_with_prefix], convert_to_numpy=True)\n",
    "\n",
    "    distances, indices = index.search(query_vec, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx == -1:  # FAISS sometimes returns -1 for no match\n",
    "            continue\n",
    "        results.append({\n",
    "            \"distance\": float(distances[0][i]),\n",
    "            \"text\": texts[idx],\n",
    "            \"meta\": metadata[idx]\n",
    "        })\n",
    "\n",
    "    return results if results else [{\"distance\": None, \"text\": \"No similar cases found.\", \"meta\": {}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18adca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  MindCheck AI Chatbot (type 'quit' to exit)\n",
      "\n",
      "You: I FIND IT HARD FOCUSING IN CLASS\n",
      "\n",
      "Assistant: I hear you. Can you tell me a bit more about how this affects you?\n",
      "You: I CANNOT PAY ATTENTION TO THE TEACHER FOR A LONG TIME\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: * **Possible Condition:** **Attention-Deficit/Hyperactivity Disorder (ADHD)**\n",
      "\n",
      "* This is suggested because difficulty focusing and paying attention for extended periods are key symptoms of ADHD.  Your statement about not being able to pay attention to the teacher for a long time aligns with this.\n",
      "\n",
      "* This information is based on the NIMH (National Institute of Mental Health) website: https://www.nimh.nih.gov\n",
      "\n",
      "*  If you'd like to know what you can do to help yourself, please ask.\n",
      "\n",
      "* **NOTE:** I encourage seeking professional help from a mental health professional for a proper diagnosis and treatment plan.\n",
      "You: WHAT SHOULD I DO?\n",
      "\n",
      "Assistant: * **Possible actions to try:**\n",
      "\n",
      "* Practice mindfulness techniques like deep breathing exercises to help improve focus.\n",
      "* Try the Pomodoro Technique:  focus intensely for short periods, then take breaks.\n",
      "* Create a quiet study environment minimizing distractions.\n",
      "* Stay organized with planners and to-do lists.\n",
      "* Prioritize tasks and break down large assignments into smaller ones.\n",
      "\n",
      "* **NOTE:** I encourage seeking professional help from a mental health professional for a proper diagnosis and treatment plan.\n",
      "You: exit\n",
      "Assistant: Goodbye ðŸ‘‹ Take care of yourself!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Generate Response (Gemini)\n",
    "# =========================\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAaynt5eBqIvaCygtu9l8UFhQHM-6-GFrQ\")\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "def generate_response(user_input, retrieved_results, history, stage):\n",
    "    \"\"\"Generate empathetic response with Gemini, using FAISS context + history.\"\"\"\n",
    "\n",
    "    # ðŸ”¹ Stage 0 â†’ only acknowledgment + gentle question\n",
    "    if stage == 0:\n",
    "        return \"I hear you. Can you tell me a bit more about how this affects you?\"\n",
    "\n",
    "    # ðŸ”¹ Stage 1+ â†’ use Gemini with FAISS context\n",
    "    context_text = \"\\n\".join(\n",
    "        [f\"- {r['meta'].get('disorder', 'Unknown')}: {r['text']}\" for r in retrieved_results]\n",
    "    )\n",
    "\n",
    "    system_instruction = \"\"\"You are MindCheck, a supportive mental health chatbot.\n",
    "    -  frame the answer Strictly in bullet point\n",
    "    - First, analyse the retrieved context and tell the most possible condition in **bold letters** (important).\n",
    "    - in next line Then,explain the reason for this suggestion based on the userâ€™s context.\n",
    "    - in next line Always mention that information is based on the NIMH (National Institute of Mental Health) website, with a clickable link: https://www.nimh.nih.gov\n",
    "    - Keep responses short, conversational.\n",
    "    - strictly Do NOT give medical advice unless the user types 'what should I do' , wait for him to write.\n",
    "    - If the user asks 'what should I do'\n",
    "    - then strictly answer what you can do , dont write the whole thing ,\n",
    "    - suggest safe self-care strategies.\n",
    "    - in next line in bold letters write NOTE : encourage seeking professional help\n",
    "\"\"\"\n",
    "\n",
    "    history_text = \"\\n\".join([f\"{msg['role'].capitalize()}: {msg['content']}\" for msg in history])\n",
    "\n",
    "    prompt = f\"\"\"{system_instruction}\n",
    "\n",
    "Conversation so far:\n",
    "{history_text}\n",
    "\n",
    "User: {user_input}\n",
    "\n",
    "Context from similar cases:\n",
    "{context_text}\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Chatbot Loop\n",
    "# =========================\n",
    "print(\"\\nðŸ§  MindCheck AI Chatbot (type 'quit' to exit)\\n\")\n",
    "\n",
    "conversation_history = []\n",
    "conversation_stage = 0  # ðŸ”¹ track stage: 0 = first input, 1+ = normal\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        print(\"Assistant: Goodbye ðŸ‘‹ Take care of yourself!\")\n",
    "        break\n",
    "\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # ðŸ”¹ Stage 0 â†’ empathy only\n",
    "    if conversation_stage == 0:\n",
    "        reply = generate_response(user_input, [], conversation_history, stage=0)\n",
    "        conversation_stage = 1  # move to next stage\n",
    "    else:\n",
    "        # Retrieve FAISS context\n",
    "        results = search(user_input, top_k=3)\n",
    "        reply = generate_response(user_input, results, conversation_history, stage=conversation_stage)\n",
    "\n",
    "    print(f\"\\nAssistant: {reply}\")\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    # ðŸ”¹ No auto-refined repetition here\n",
    "    # Instead, let the user naturally continue typing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86015118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-telegram-bot\n",
      "  Obtaining dependency information for python-telegram-bot from https://files.pythonhosted.org/packages/e5/54/0955bd46a1e046169500e129c7883664b6675d580074d68823485e4d5de1/python_telegram_bot-22.3-py3-none-any.whl.metadata\n",
      "  Downloading python_telegram_bot-22.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-telegram-bot) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.2.0)\n",
      "Downloading python_telegram_bot-22.3-py3-none-any.whl (717 kB)\n",
      "   ---------------------------------------- 0.0/717.1 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/717.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 143.4/717.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 204.8/717.1 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 337.9/717.1 kB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 419.8/717.1 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 573.4/717.1 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 665.6/717.1 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 717.1/717.1 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: python-telegram-bot\n",
      "Successfully installed python-telegram-bot-22.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-telegram-bot --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea34e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ce26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is running...\n"
     ]
    }
   ],
   "source": [
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters\n",
    "\n",
    "# Your token from BotFather\n",
    "TOKEN = \"8453597341:AAFHdF43XY42KhytmPwkgw4n1Kgu1qQgsJ4\"\n",
    "\n",
    "# Start command\n",
    "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    await update.message.reply_text(\"Hello! Iâ€™m your bot, send me something.\")\n",
    "\n",
    "# Echo (replies with same text)\n",
    "async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    user_text = update.message.text\n",
    "    # ðŸ”¥ Here you put your custom logic (like your DP code)\n",
    "    await update.message.reply_text(f\"You said: {user_text}\")\n",
    "\n",
    "def main():\n",
    "    app = Application.builder().token(TOKEN).build()\n",
    "\n",
    "    app.add_handler(CommandHandler(\"start\", start))\n",
    "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))\n",
    "\n",
    "    print(\"Bot is running...\")\n",
    "    app.run_polling()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006c4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
